{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROugh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from pytesseract) (10.4.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pytesseract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-ocr in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (0.9.3)\n",
      "Requirement already satisfied: editdistance in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-ocr) (0.8.1)\n",
      "Requirement already satisfied: efficientnet==1.0.0 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-ocr) (1.0.0)\n",
      "Requirement already satisfied: essential_generators in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-ocr) (1.0)\n",
      "Requirement already satisfied: fonttools in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-ocr) (4.53.1)\n",
      "Requirement already satisfied: imgaug in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-ocr) (0.4.0)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-ocr) (1.3.0.post5)\n",
      "Requirement already satisfied: shapely in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-ocr) (2.0.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-ocr) (4.66.5)\n",
      "Requirement already satisfied: validators in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-ocr) (0.34.0)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from efficientnet==1.0.0->keras-ocr) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from efficientnet==1.0.0->keras-ocr) (0.24.0)\n",
      "Requirement already satisfied: six in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from imgaug->keras-ocr) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from imgaug->keras-ocr) (2.1.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from imgaug->keras-ocr) (1.14.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from imgaug->keras-ocr) (10.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from imgaug->keras-ocr) (3.9.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from imgaug->keras-ocr) (4.10.0.84)\n",
      "Requirement already satisfied: imageio in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from imgaug->keras-ocr) (2.35.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from tqdm->keras-ocr) (0.4.6)\n",
      "Requirement already satisfied: h5py in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (3.11.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (3.3)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from matplotlib->imgaug->keras-ocr) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from matplotlib->imgaug->keras-ocr) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from matplotlib->imgaug->keras-ocr) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from matplotlib->imgaug->keras-ocr) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from matplotlib->imgaug->keras-ocr) (2.9.0.post0)\n"
     ]
    }
   ],
   "source": [
    "! pip install keras-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Using cached easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (0.19.1)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (1.14.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (2.1.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (10.4.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (0.24.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (0.6.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (2.0.6)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (74.1.2)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->easyocr) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->easyocr) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->easyocr) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Using cached easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python-headless, easyocr\n",
      "Successfully installed easyocr-1.7.1 opencv-python-headless-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "! pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: doctr[torch] in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from doctr[torch]) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from doctr[torch]) (2.32.3)\n",
      "Requirement already satisfied: cryptography in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from doctr[torch]) (43.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from cryptography->doctr[torch]) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from requests->doctr[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from requests->doctr[torch]) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from requests->doctr[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from requests->doctr[torch]) (2024.8.30)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from cffi>=1.12->cryptography->doctr[torch]) (2.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: doctr 1.9.0 does not provide the extra 'torch'\n"
     ]
    }
   ],
   "source": [
    "! pip install doctr[torch] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>tesseract</th>\n",
       "      <th>doctr</th>\n",
       "      <th>easyocr</th>\n",
       "      <th>kerasocr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61+40BOJSQ...</td>\n",
       "      <td>574059</td>\n",
       "      <td>depth</td>\n",
       "      <td>33.0 centimetre</td>\n",
       "      <td>A4 SIZE\\n\\n_———\\n\\n23CM\\n\\n33CM\\n</td>\n",
       "      <td>A4 SIZE \\nS \\n23CM \\n33CM \\n</td>\n",
       "      <td>A4 SIZE 23CM 33CM</td>\n",
       "      <td>size a4 23cm 33cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/516pgePFER...</td>\n",
       "      <td>573063</td>\n",
       "      <td>depth</td>\n",
       "      <td>7.1 inch</td>\n",
       "      <td>7.Ain\\n\\n \\n\\nProduct Size\\n\\naseeae pet\\nDA f...</td>\n",
       "      <td>Product Size \\nPlanner Papes \\nJUSTFORYOU \\nAF...</td>\n",
       "      <td>Product Size Planner Papes JUSTFOR YOU So ulan...</td>\n",
       "      <td>product size planner papes just for you sotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/618UHY-K+p...</td>\n",
       "      <td>675317</td>\n",
       "      <td>depth</td>\n",
       "      <td>69.0 millimetre</td>\n",
       "      <td>a&amp;m~\\nLeapMars\\nwa\\n\\n   \\n\\nAmmn/Tu6in |\\n\\n6...</td>\n",
       "      <td>LeapMars \\nNE \\n \\nA \\n4mm/D.bin \\n1 \\n69mm/2....</td>\n",
       "      <td>LeapMars 4mm/I.IEin E9mm/2.Tin @IBkg/0.4lb 2Em...</td>\n",
       "      <td>leapmars zommfaoin smmizlin ammligin gammilin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51DwjVJNNo...</td>\n",
       "      <td>329793</td>\n",
       "      <td>depth</td>\n",
       "      <td>21.0 centimetre</td>\n",
       "      <td>\\n</td>\n",
       "      <td>* - \\nc \\n- \\n</td>\n",
       "      <td>2lcm Ve</td>\n",
       "      <td>dg 21cm san</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51T8JAr6Vs...</td>\n",
       "      <td>734280</td>\n",
       "      <td>depth</td>\n",
       "      <td>28.5 centimetre</td>\n",
       "      <td>—_ mm\\n</td>\n",
       "      <td>5 \\n12 \\n28.5 cm \\n</td>\n",
       "      <td>6 cm 28.5</td>\n",
       "      <td>s cm 5 281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61+40BOJSQ...    574059       depth   \n",
       "1  https://m.media-amazon.com/images/I/516pgePFER...    573063       depth   \n",
       "2  https://m.media-amazon.com/images/I/618UHY-K+p...    675317       depth   \n",
       "3  https://m.media-amazon.com/images/I/51DwjVJNNo...    329793       depth   \n",
       "4  https://m.media-amazon.com/images/I/51T8JAr6Vs...    734280       depth   \n",
       "\n",
       "      entity_value                                          tesseract  \\\n",
       "0  33.0 centimetre                 A4 SIZE\\n\\n_———\\n\\n23CM\\n\\n33CM\\n\n",
       "   \n",
       "1         7.1 inch  7.Ain\\n\\n \\n\\nProduct Size\\n\\naseeae pet\\nDA f...   \n",
       "2  69.0 millimetre  a&m~\\nLeapMars\\nwa\\n\\n   \\n\\nAmmn/Tu6in |\\n\\n6...   \n",
       "3  21.0 centimetre                                                \\n\n",
       "   \n",
       "4  28.5 centimetre                                           —_ mm\\n\n",
       "   \n",
       "\n",
       "                                               doctr  \\\n",
       "0                       A4 SIZE \\nS \\n23CM \\n33CM \\n   \n",
       "1  Product Size \\nPlanner Papes \\nJUSTFORYOU \\nAF...   \n",
       "2  LeapMars \\nNE \\n \\nA \\n4mm/D.bin \\n1 \\n69mm/2....   \n",
       "3                                     * - \\nc \\n- \\n   \n",
       "4                                5 \\n12 \\n28.5 cm \\n   \n",
       "\n",
       "                                             easyocr  \\\n",
       "0                                  A4 SIZE 23CM 33CM   \n",
       "1  Product Size Planner Papes JUSTFOR YOU So ulan...   \n",
       "2  LeapMars 4mm/I.IEin E9mm/2.Tin @IBkg/0.4lb 2Em...   \n",
       "3                                            2lcm Ve   \n",
       "4                                          6 cm 28.5   \n",
       "\n",
       "                                            kerasocr  \n",
       "0                                  size a4 23cm 33cm  \n",
       "1  product size planner papes just for you sotati...  \n",
       "2  leapmars zommfaoin smmizlin ammligin gammilin ...  \n",
       "3                                        dg 21cm san  \n",
       "4                                         s cm 5 281  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://m.media-amazon.com/images/I/61+40BOJSQL.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_url = df.image_link[0]\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Download the image\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tesseract OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A4 SIZE\n",
      "\n",
      "_———\n",
      "\n",
      "23CM\n",
      "\n",
      "33CM\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def tesseract_ocr(img):\n",
    "    return pytesseract.image_to_string(img) \n",
    "\n",
    "text = tesseract_ocr(img) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (0.19.1)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (4.10.0.84)\n",
      "Requirement already satisfied: scipy in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (1.14.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (2.1.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (10.4.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (0.24.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (0.6.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (2.0.6)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from torch->easyocr) (74.1.2)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->easyocr) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->easyocr) (2024.8.30)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->easyocr) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cvish\\desktop\\amazon ml\\resources\\myenv\\lib\\site-packages (from sympy->torch->easyocr) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |█████---------------------------------------------| 11.1% Complete"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize EasyOCR Reader\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43measyocr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Replace 'your_csv_file.csv' with your actual CSV file path\u001b[39;00m\n\u001b[0;32m      9\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/ocr.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cvish\\Desktop\\amazon ML\\resources\\myenv\\Lib\\site-packages\\easyocr\\easyocr.py:92\u001b[0m, in \u001b[0;36mReader.__init__\u001b[1;34m(self, lang_list, gpu, model_storage_directory, user_network_directory, detect_network, recog_network, download_enabled, detector, recognizer, verbose, quantize, cudnn_benchmark)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcudnn_benchmark\u001b[38;5;241m=\u001b[39mcudnn_benchmark\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detector:\n\u001b[1;32m---> 92\u001b[0m     detector_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetDetectorPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetect_network\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# recognition model\u001b[39;00m\n\u001b[0;32m     95\u001b[0m separator_list \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\cvish\\Desktop\\amazon ML\\resources\\myenv\\Lib\\site-packages\\easyocr\\easyocr.py:253\u001b[0m, in \u001b[0;36mReader.getDetectorPath\u001b[1;34m(self, detect_network)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and downloads disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m detector_path)\n\u001b[0;32m    251\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading detection model, please wait. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    252\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis may take several minutes depending upon your network connection.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 253\u001b[0m \u001b[43mdownload_and_unzip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetection_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_network\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetection_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_network\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilename\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_storage_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m calculate_md5(detector_path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetection_models[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetect_network][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd5sum\u001b[39m\u001b[38;5;124m'\u001b[39m], corrupt_msg\n\u001b[0;32m    255\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownload complete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cvish\\Desktop\\amazon ML\\resources\\myenv\\Lib\\site-packages\\easyocr\\utils.py:628\u001b[0m, in \u001b[0;36mdownload_and_unzip\u001b[1;34m(url, filename, model_storage_directory, verbose)\u001b[0m\n\u001b[0;32m    626\u001b[0m zip_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_storage_directory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    627\u001b[0m reporthook \u001b[38;5;241m=\u001b[39m printProgressBar(prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgress:\u001b[39m\u001b[38;5;124m'\u001b[39m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComplete\u001b[39m\u001b[38;5;124m'\u001b[39m, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreporthook\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ZipFile(zip_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zipObj:\n\u001b[0;32m    630\u001b[0m     zipObj\u001b[38;5;241m.\u001b[39mextract(filename, model_storage_directory)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[0;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m block \u001b[38;5;241m:=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    269\u001b[0m     read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[0;32m    270\u001b[0m     tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import csv\n",
    "\n",
    "\n",
    "# Initialize EasyOCR Reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Replace 'your_csv_file.csv' with your actual CSV file path\n",
    "csv_file_path = '/content/ocr.csv'\n",
    "\n",
    "# Assuming the CSV has a header row and the URLs are in a column named 'image_url'\n",
    "with open(csv_file_path, 'r', newline='') as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile)\n",
    "\n",
    "    # Read the first row only\n",
    "    row = next(csv_reader)\n",
    "    image_url = row['image_link'] # Get the URL from the 'image_url' column\n",
    "\n",
    "    try:\n",
    "        # Read image from URL\n",
    "        response = requests.get(image_url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_img = img.convert('L')\n",
    "        gray_img_np = np.array(gray_img)\n",
    "\n",
    "        # Perform OCR\n",
    "        results = reader.readtext(gray_img_np)\n",
    "\n",
    "        # Extract text\n",
    "        detected_text = \" \".join([text for (_, text, _) in results])\n",
    "        print(f\"URL: {image_url}\")\n",
    "        print(f\"Extracted Text: {detected_text}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading image from {image_url}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>tesseract</th>\n",
       "      <th>doctr</th>\n",
       "      <th>easyocr</th>\n",
       "      <th>kerasocr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61+40BOJSQ...</td>\n",
       "      <td>574059</td>\n",
       "      <td>depth</td>\n",
       "      <td>33.0 centimetre</td>\n",
       "      <td>A4 SIZE\\n\\n_———\\n\\n23CM\\n\\n33CM\\n</td>\n",
       "      <td>A4 SIZE \\nS \\n23CM \\n33CM \\n</td>\n",
       "      <td>A4 SIZE 23CM 33CM</td>\n",
       "      <td>size a4 23cm 33cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/516pgePFER...</td>\n",
       "      <td>573063</td>\n",
       "      <td>depth</td>\n",
       "      <td>7.1 inch</td>\n",
       "      <td>7.Ain\\n\\n \\n\\nProduct Size\\n\\naseeae pet\\nDA f...</td>\n",
       "      <td>Product Size \\nPlanner Papes \\nJUSTFORYOU \\nAF...</td>\n",
       "      <td>Product Size Planner Papes JUSTFOR YOU So ulan...</td>\n",
       "      <td>product size planner papes just for you sotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/618UHY-K+p...</td>\n",
       "      <td>675317</td>\n",
       "      <td>depth</td>\n",
       "      <td>69.0 millimetre</td>\n",
       "      <td>a&amp;m~\\nLeapMars\\nwa\\n\\n   \\n\\nAmmn/Tu6in |\\n\\n6...</td>\n",
       "      <td>LeapMars \\nNE \\n \\nA \\n4mm/D.bin \\n1 \\n69mm/2....</td>\n",
       "      <td>LeapMars 4mm/I.IEin E9mm/2.Tin @IBkg/0.4lb 2Em...</td>\n",
       "      <td>leapmars zommfaoin smmizlin ammligin gammilin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51DwjVJNNo...</td>\n",
       "      <td>329793</td>\n",
       "      <td>depth</td>\n",
       "      <td>21.0 centimetre</td>\n",
       "      <td>\\n</td>\n",
       "      <td>* - \\nc \\n- \\n</td>\n",
       "      <td>2lcm Ve</td>\n",
       "      <td>dg 21cm san</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51T8JAr6Vs...</td>\n",
       "      <td>734280</td>\n",
       "      <td>depth</td>\n",
       "      <td>28.5 centimetre</td>\n",
       "      <td>—_ mm\\n</td>\n",
       "      <td>5 \\n12 \\n28.5 cm \\n</td>\n",
       "      <td>6 cm 28.5</td>\n",
       "      <td>s cm 5 281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61+40BOJSQ...    574059       depth   \n",
       "1  https://m.media-amazon.com/images/I/516pgePFER...    573063       depth   \n",
       "2  https://m.media-amazon.com/images/I/618UHY-K+p...    675317       depth   \n",
       "3  https://m.media-amazon.com/images/I/51DwjVJNNo...    329793       depth   \n",
       "4  https://m.media-amazon.com/images/I/51T8JAr6Vs...    734280       depth   \n",
       "\n",
       "      entity_value                                          tesseract  \\\n",
       "0  33.0 centimetre                 A4 SIZE\\n\\n_———\\n\\n23CM\\n\\n33CM\\n\n",
       "   \n",
       "1         7.1 inch  7.Ain\\n\\n \\n\\nProduct Size\\n\\naseeae pet\\nDA f...   \n",
       "2  69.0 millimetre  a&m~\\nLeapMars\\nwa\\n\\n   \\n\\nAmmn/Tu6in |\\n\\n6...   \n",
       "3  21.0 centimetre                                                \\n\n",
       "   \n",
       "4  28.5 centimetre                                           —_ mm\\n\n",
       "   \n",
       "\n",
       "                                               doctr  \\\n",
       "0                       A4 SIZE \\nS \\n23CM \\n33CM \\n   \n",
       "1  Product Size \\nPlanner Papes \\nJUSTFORYOU \\nAF...   \n",
       "2  LeapMars \\nNE \\n \\nA \\n4mm/D.bin \\n1 \\n69mm/2....   \n",
       "3                                     * - \\nc \\n- \\n   \n",
       "4                                5 \\n12 \\n28.5 cm \\n   \n",
       "\n",
       "                                             easyocr  \\\n",
       "0                                  A4 SIZE 23CM 33CM   \n",
       "1  Product Size Planner Papes JUSTFOR YOU So ulan...   \n",
       "2  LeapMars 4mm/I.IEin E9mm/2.Tin @IBkg/0.4lb 2Em...   \n",
       "3                                            2lcm Ve   \n",
       "4                                          6 cm 28.5   \n",
       "\n",
       "                                            kerasocr  \n",
       "0                                  size a4 23cm 33cm  \n",
       "1  product size planner papes just for you sotati...  \n",
       "2  leapmars zommfaoin smmizlin ammligin gammilin ...  \n",
       "3                                        dg 21cm san  \n",
       "4                                         s cm 5 281  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>tesseract</th>\n",
       "      <th>doctr</th>\n",
       "      <th>easyocr</th>\n",
       "      <th>kerasocr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61+40BOJSQ...</td>\n",
       "      <td>574059</td>\n",
       "      <td>depth</td>\n",
       "      <td>33.0 centimetre</td>\n",
       "      <td>A4 SIZE _——— 23CM 33CM</td>\n",
       "      <td>A4 SIZE S 23CM 33CM</td>\n",
       "      <td>A4 SIZE 23CM 33CM</td>\n",
       "      <td>size a4 23cm 33cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/516pgePFER...</td>\n",
       "      <td>573063</td>\n",
       "      <td>depth</td>\n",
       "      <td>7.1 inch</td>\n",
       "      <td>7.Ain Product Size aseeae pet DA fei Souton to...</td>\n",
       "      <td>Product Size Planner Papes JUSTFORYOU AFlexble...</td>\n",
       "      <td>Product Size Planner Papes JUSTFOR YOU So ulan...</td>\n",
       "      <td>product size planner papes just for you sotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/618UHY-K+p...</td>\n",
       "      <td>675317</td>\n",
       "      <td>depth</td>\n",
       "      <td>69.0 millimetre</td>\n",
       "      <td>a&amp;m~ LeapMars wa Ammn Tu6in 69mm 2.7in O.18kg ...</td>\n",
       "      <td>LeapMars NE A 4mm D.bin 1 69mm 2.7in 0.18kg 0.41b</td>\n",
       "      <td>LeapMars 4mm I.IEin E9mm 2.Tin IBkg 0.4lb 2Emm...</td>\n",
       "      <td>leapmars zommfaoin smmizlin ammligin gammilin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51DwjVJNNo...</td>\n",
       "      <td>329793</td>\n",
       "      <td>depth</td>\n",
       "      <td>21.0 centimetre</td>\n",
       "      <td></td>\n",
       "      <td>* - c -</td>\n",
       "      <td>2lcm Ve</td>\n",
       "      <td>dg 21cm san</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51T8JAr6Vs...</td>\n",
       "      <td>734280</td>\n",
       "      <td>depth</td>\n",
       "      <td>28.5 centimetre</td>\n",
       "      <td>—_ mm</td>\n",
       "      <td>5 12 28.5 cm</td>\n",
       "      <td>6 cm 28.5</td>\n",
       "      <td>s cm 5 281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61+40BOJSQ...    574059       depth   \n",
       "1  https://m.media-amazon.com/images/I/516pgePFER...    573063       depth   \n",
       "2  https://m.media-amazon.com/images/I/618UHY-K+p...    675317       depth   \n",
       "3  https://m.media-amazon.com/images/I/51DwjVJNNo...    329793       depth   \n",
       "4  https://m.media-amazon.com/images/I/51T8JAr6Vs...    734280       depth   \n",
       "\n",
       "      entity_value                                          tesseract  \\\n",
       "0  33.0 centimetre                             A4 SIZE _——— 23CM 33CM   \n",
       "1         7.1 inch  7.Ain Product Size aseeae pet DA fei Souton to...   \n",
       "2  69.0 millimetre  a&m~ LeapMars wa Ammn Tu6in 69mm 2.7in O.18kg ...   \n",
       "3  21.0 centimetre                                                      \n",
       "4  28.5 centimetre                                              —_ mm   \n",
       "\n",
       "                                               doctr  \\\n",
       "0                                A4 SIZE S 23CM 33CM   \n",
       "1  Product Size Planner Papes JUSTFORYOU AFlexble...   \n",
       "2  LeapMars NE A 4mm D.bin 1 69mm 2.7in 0.18kg 0.41b   \n",
       "3                                            * - c -   \n",
       "4                                       5 12 28.5 cm   \n",
       "\n",
       "                                             easyocr  \\\n",
       "0                                  A4 SIZE 23CM 33CM   \n",
       "1  Product Size Planner Papes JUSTFOR YOU So ulan...   \n",
       "2  LeapMars 4mm I.IEin E9mm 2.Tin IBkg 0.4lb 2Emm...   \n",
       "3                                            2lcm Ve   \n",
       "4                                          6 cm 28.5   \n",
       "\n",
       "                                            kerasocr  \n",
       "0                                  size a4 23cm 33cm  \n",
       "1  product size planner papes just for you sotati...  \n",
       "2  leapmars zommfaoin smmizlin ammligin gammilin ...  \n",
       "3                                        dg 21cm san  \n",
       "4                                         s cm 5 281  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Function to clean text by removing special characters and extra spaces\n",
    "def clean_text(text):\n",
    "    # Remove special characters and extra spaces\n",
    "    # text = re.sub(r'[|@%]', '', text)  # Remove |, @, and %\n",
    "    # text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "    text = re.sub(r'[|@%/\\s]+', ' ', text)  # Replace multiple spaces with single space\n",
    "    return text.strip()  # Remove leading and trailing spaces\n",
    "\n",
    "columns_to_clean = ['tesseract', 'doctr', 'easyocr', 'kerasocr']\n",
    "for col in columns_to_clean:\n",
    "    df[col] = df[col].astype(str).apply(clean_text)  # Convert to string first\n",
    "\n",
    "# Show the cleaned dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Packing List - G CRED. - 0 HIRO i - 2 0 R OPLE E G G 5 ERCN G 35 ERED CRED 4 - Sase 0 Packing Box 2) 2.5 Drive Enclosure (3 User Manual 4 EVA Foam Pad 5[ Data Cable'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.doctr[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>tesseract</th>\n",
       "      <th>doctr</th>\n",
       "      <th>easyocr</th>\n",
       "      <th>kerasocr</th>\n",
       "      <th>ensemble_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61+40BOJSQ...</td>\n",
       "      <td>574059</td>\n",
       "      <td>depth</td>\n",
       "      <td>33.0 centimetre</td>\n",
       "      <td>A4 SIZE _——— 23CM 33CM</td>\n",
       "      <td>A4 SIZE S 23CM 33CM</td>\n",
       "      <td>A4 SIZE 23CM 33CM</td>\n",
       "      <td>size a4 23cm 33cm</td>\n",
       "      <td>size a4 23cm 33cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/516pgePFER...</td>\n",
       "      <td>573063</td>\n",
       "      <td>depth</td>\n",
       "      <td>7.1 inch</td>\n",
       "      <td>7.Ain Product Size aseeae pet DA fei Souton to...</td>\n",
       "      <td>Product Size Planner Papes JUSTFORYOU AFlexble...</td>\n",
       "      <td>Product Size Planner Papes JUSTFOR YOU So ulan...</td>\n",
       "      <td>product size planner papes just for you sotati...</td>\n",
       "      <td>7.Ain Product Size aseeae pet DA fei Souton to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/618UHY-K+p...</td>\n",
       "      <td>675317</td>\n",
       "      <td>depth</td>\n",
       "      <td>69.0 millimetre</td>\n",
       "      <td>a&amp;m~ LeapMars wa Ammn Tu6in 69mm 2.7in O.18kg ...</td>\n",
       "      <td>LeapMars NE A 4mm D.bin 1 69mm 2.7in 0.18kg 0.41b</td>\n",
       "      <td>LeapMars 4mm I.IEin E9mm 2.Tin IBkg 0.4lb 2Emm...</td>\n",
       "      <td>leapmars zommfaoin smmizlin ammligin gammilin ...</td>\n",
       "      <td>leapmars zommfaoin smmizlin ammligin gammilin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51DwjVJNNo...</td>\n",
       "      <td>329793</td>\n",
       "      <td>depth</td>\n",
       "      <td>21.0 centimetre</td>\n",
       "      <td></td>\n",
       "      <td>* - c -</td>\n",
       "      <td>2lcm Ve</td>\n",
       "      <td>dg 21cm san</td>\n",
       "      <td>2lcm Ve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/51T8JAr6Vs...</td>\n",
       "      <td>734280</td>\n",
       "      <td>depth</td>\n",
       "      <td>28.5 centimetre</td>\n",
       "      <td>—_ mm</td>\n",
       "      <td>5 12 28.5 cm</td>\n",
       "      <td>6 cm 28.5</td>\n",
       "      <td>s cm 5 281</td>\n",
       "      <td>5 12 28.5 cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61+40BOJSQ...    574059       depth   \n",
       "1  https://m.media-amazon.com/images/I/516pgePFER...    573063       depth   \n",
       "2  https://m.media-amazon.com/images/I/618UHY-K+p...    675317       depth   \n",
       "3  https://m.media-amazon.com/images/I/51DwjVJNNo...    329793       depth   \n",
       "4  https://m.media-amazon.com/images/I/51T8JAr6Vs...    734280       depth   \n",
       "\n",
       "      entity_value                                          tesseract  \\\n",
       "0  33.0 centimetre                             A4 SIZE _——— 23CM 33CM   \n",
       "1         7.1 inch  7.Ain Product Size aseeae pet DA fei Souton to...   \n",
       "2  69.0 millimetre  a&m~ LeapMars wa Ammn Tu6in 69mm 2.7in O.18kg ...   \n",
       "3  21.0 centimetre                                                      \n",
       "4  28.5 centimetre                                              —_ mm   \n",
       "\n",
       "                                               doctr  \\\n",
       "0                                A4 SIZE S 23CM 33CM   \n",
       "1  Product Size Planner Papes JUSTFORYOU AFlexble...   \n",
       "2  LeapMars NE A 4mm D.bin 1 69mm 2.7in 0.18kg 0.41b   \n",
       "3                                            * - c -   \n",
       "4                                       5 12 28.5 cm   \n",
       "\n",
       "                                             easyocr  \\\n",
       "0                                  A4 SIZE 23CM 33CM   \n",
       "1  Product Size Planner Papes JUSTFOR YOU So ulan...   \n",
       "2  LeapMars 4mm I.IEin E9mm 2.Tin IBkg 0.4lb 2Emm...   \n",
       "3                                            2lcm Ve   \n",
       "4                                          6 cm 28.5   \n",
       "\n",
       "                                            kerasocr  \\\n",
       "0                                  size a4 23cm 33cm   \n",
       "1  product size planner papes just for you sotati...   \n",
       "2  leapmars zommfaoin smmizlin ammligin gammilin ...   \n",
       "3                                        dg 21cm san   \n",
       "4                                         s cm 5 281   \n",
       "\n",
       "                                     ensemble_output  \n",
       "0                                  size a4 23cm 33cm  \n",
       "1  7.Ain Product Size aseeae pet DA fei Souton to...  \n",
       "2  leapmars zommfaoin smmizlin ammligin gammilin ...  \n",
       "3                                            2lcm Ve  \n",
       "4                                       5 12 28.5 cm  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def ensemble_ocr(df):\n",
    "    \"\"\"\n",
    "    Ensemble OCR approach that chooses the best output based on \n",
    "    similarity to the 'entity_value' (ground truth) and text length.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with OCR outputs from different models.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with a new 'ensemble_output' column containing the best OCR output.\n",
    "    \"\"\"\n",
    "\n",
    "    ocr_cols = ['tesseract', 'doctr', 'easyocr', 'kerasocr']\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        best_similarity = 0\n",
    "        best_output = None\n",
    "\n",
    "        for ocr_col in ocr_cols:\n",
    "            if pd.notna(row[ocr_col]):\n",
    "                similarity = fuzz.ratio(row[ocr_col], row['entity_value'])\n",
    "\n",
    "                if similarity > best_similarity or (similarity == best_similarity and \n",
    "                                                best_output is not None and \n",
    "                                                len(row[ocr_col]) > len(best_output)):\n",
    "                    best_similarity = similarity\n",
    "                    best_output = row[ocr_col]\n",
    "\n",
    "        # Default to 'easyocr' if best_output is still None\n",
    "        if best_output is None:\n",
    "            best_output = row['easyocr']  \n",
    "\n",
    "        df.loc[index, 'ensemble_output'] = best_output\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = ensemble_ocr(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_final_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
